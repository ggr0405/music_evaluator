import librosa
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
from scipy.spatial.distance import euclidean as norm
from fastdtw import fastdtw
import os

def compare_audio2(ref_path, user_path):
    # å›ºå®šé‡‡æ ·ç‡åŠ è½½
    sr_target = 16000
    y_ref, sr_ref = librosa.load(ref_path, sr=sr_target)
    y_user, sr_user = librosa.load(user_path, sr=sr_target)

    # MFCC ç‰¹å¾
    ref_mfcc = librosa.feature.mfcc(y=y_ref, sr=sr_ref, n_mfcc=20)
    user_mfcc = librosa.feature.mfcc(y=y_user, sr=sr_user, n_mfcc=20)

    # DTW å¯¹é½
    distance, alignment = fastdtw(ref_mfcc.T, user_mfcc.T, dist=norm)

    # åŸºé¢‘æå–
    f0_ref, _, _ = librosa.pyin(y_ref, sr=sr_ref,
                               fmin=librosa.note_to_hz('C2'),
                               fmax=librosa.note_to_hz('C7'))
    f0_user, _, _ = librosa.pyin(y_user, sr=sr_user,
                                fmin=librosa.note_to_hz('C2'),
                                fmax=librosa.note_to_hz('C7'))

    # åŸºé¢‘åŒæ­¥å¯¹é½
    f0_ref_aligned = []
    f0_user_aligned = []
    for i, j in alignment:
        if i < len(f0_ref) and j < len(f0_user):
            if not (np.isnan(f0_ref[i]) or np.isnan(f0_user[j])):
                f0_ref_aligned.append(f0_ref[i])
                f0_user_aligned.append(f0_user[j])
    f0_ref_aligned = np.array(f0_ref_aligned)
    f0_user_aligned = np.array(f0_user_aligned)

    pitch_error = np.mean(np.abs(f0_ref_aligned - f0_user_aligned)) if len(f0_ref_aligned) > 0 else 0

    # èŠ‚å¥è¯¯å·®ï¼ˆç§’ï¼‰
    ref_times = librosa.frames_to_time([i for i, j in alignment], sr=sr_ref)
    user_times = librosa.frames_to_time([j for i, j in alignment], sr=sr_user)
    time_diffs = user_times - ref_times
    rhythm_error = np.std(time_diffs) if len(time_diffs) > 1 else 0

    # è¯„åˆ†è®¡ç®—
    rhythm_score = max(0, 100 - rhythm_error * 100)
    pitch_score = max(0, 100 - pitch_error / 2)
    overall_score = round(pitch_score * 0.8 + rhythm_score * 0.2)

    # å»ºè®®
    suggestions = []
    if pitch_score < 85:
        suggestions.append("ğŸµ è¯·æé«˜éŸ³å‡†å‡†ç¡®åº¦ã€‚")
    if rhythm_score < 85:
        suggestions.append("ğŸ¥ è¯·åŠ å¼ºèŠ‚å¥çš„ç²¾å‡†æ€§ã€‚")
    if overall_score < 80:
        suggestions.append("ğŸ¯ éœ€è¦æ›´å¤šç»ƒä¹ ä»¥æå‡å‡†ç¡®åº¦å’ŒèŠ‚å¥æ„Ÿã€‚")

    # åˆ†æ®µè¯„åˆ† - åŸºäºåŸºé¢‘è¯¯å·®è®¡ç®—éŸ³å‡†åˆ†æ•°
    segment_size = 10
    pitch_segment_scores_f0 = []
    rhythm_segment_scores = []

    for i in range(0, len(alignment), segment_size):
        segment = alignment[i:i+segment_size]
        if len(segment) == 0:
            continue

        # éŸ³å‡†åˆ†æ®µè¯„åˆ†ï¼šåŸºé¢‘ç»å¯¹è¯¯å·®å¹³å‡ï¼Œè½¬æˆåˆ†æ•°
        seg_f0_ref = []
        seg_f0_user = []
        for idx_ref, idx_user in segment:
            if idx_ref < len(f0_ref) and idx_user < len(f0_user):
                if not (np.isnan(f0_ref[idx_ref]) or np.isnan(f0_user[idx_user])):
                    seg_f0_ref.append(f0_ref[idx_ref])
                    seg_f0_user.append(f0_user[idx_user])
        if len(seg_f0_ref) > 0:
            seg_pitch_err = np.mean(np.abs(np.array(seg_f0_ref) - np.array(seg_f0_user)))
            pitch_seg_score = max(0, 100 - seg_pitch_err / 2)
        else:
            pitch_seg_score = 0
        pitch_segment_scores_f0.append(pitch_seg_score)

        # èŠ‚å¥åˆ†æ®µè¯„åˆ†ï¼šæ—¶é—´å·®æ ‡å‡†å·®è½¬åˆ†æ•°
        seg_ref_times = librosa.frames_to_time([idx_ref for idx_ref, _ in segment], sr=sr_ref)
        seg_user_times = librosa.frames_to_time([idx_user for _, idx_user in segment], sr=sr_user)
        seg_time_diffs = seg_user_times - seg_ref_times
        seg_rhythm_err = np.std(seg_time_diffs) if len(seg_time_diffs) > 1 else 0
        rhythm_seg_score = max(0, 100 - seg_rhythm_err * 100)
        rhythm_segment_scores.append(rhythm_seg_score)

    # ç»˜å›¾
    svg_path = plot_segment_scores_bar(pitch_segment_scores_f0, rhythm_segment_scores)

    return {
        "score": overall_score,
        "pitch_error": round(pitch_error, 2),
        "rhythm_error": round(rhythm_error, 4),
        "rhythm_score": round(rhythm_score),
        "pitch_score": round(pitch_score),
        "suggestions": suggestions,
        "segment_scores_pitch": pitch_segment_scores_f0,
        "segment_scores_rhythm": rhythm_segment_scores,
        "chart": svg_path
    }


def plot_segment_scores_bar(pitch_scores, rhythm_scores):
    import matplotlib.pyplot as plt
    import numpy as np
    import os

    os.makedirs("data/out", exist_ok=True)
    svg_path = "data/out/segment_scores.svg"

    segments = np.arange(len(pitch_scores))

    plt.figure(figsize=(20, 6))  # å®½åº¦æ˜¯é»˜è®¤çš„2å€
    bar_width = 0.6

    plt.bar(segments, pitch_scores, width=bar_width, label="Pitch Score", color='tab:blue')
    plt.bar(segments, rhythm_scores, width=bar_width, bottom=pitch_scores, label="Rhythm Score", color='tab:orange')

    plt.xlabel("Time Segment")
    plt.ylabel("Score (0~100)")
    plt.title("Segment Scores: Pitch and Rhythm")
    plt.ylim(0, 200)  # å åŠ æœ€å¤§200
    plt.xticks(segments)
    plt.legend()
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.savefig(svg_path, format='svg')
    plt.close()

    return svg_path


if __name__ == "__main__":
    import sys
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python compare_audio2.py å‚è€ƒéŸ³é¢‘.mp3 ç”¨æˆ·éŸ³é¢‘.mp3")
        sys.exit(1)

    ref_path = sys.argv[1]
    user_path = sys.argv[2]

    result = compare_audio2(ref_path, user_path)

    print(f"ç»¼åˆè¯„åˆ†: {result['score']}ï¼ˆèŒƒå›´0~100ï¼Œè¶Šé«˜è¶Šå¥½ï¼Œç»¼åˆè€ƒè™‘éŸ³å‡†å’ŒèŠ‚å¥ï¼‰")
    print(f"éŸ³å‡†è¯¯å·®: {result['pitch_error']} Hzï¼ˆå¹³å‡åŸºé¢‘å·®ï¼Œè¶Šä½è¶Šå¥½ï¼‰")
    print(f"èŠ‚å¥è¯¯å·®: {result['rhythm_error']} ç§’ï¼ˆæ—¶é—´å·®æ ‡å‡†å·®ï¼Œè¶Šä½è¶Šå¥½ï¼‰")
    print(f"èŠ‚å¥è¯„åˆ†: {result['rhythm_score']}ï¼ˆèŒƒå›´0~100ï¼Œè¶Šé«˜è¶Šå¥½ï¼ŒåŸºäºèŠ‚å¥è¯¯å·®è®¡ç®—ï¼‰")
    print("å»ºè®®:")
    for s in result['suggestions']:
        print(f" - {s}")
    print("åˆ†æ®µè¯„åˆ†å›¾å·²ä¿å­˜è‡³ï¼š", result["chart"])
